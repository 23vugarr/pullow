{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9_Qobl_74ptW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vNDbudr5Su1",
        "outputId": "f20e2f99-1705-4b58-98a2-0da9e8157a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len of tables:  26\n"
          ]
        }
      ],
      "source": [
        "url = \"https://yeniemlak.az/bakida-evlerin-qiymeti?t=2018\"\n",
        "html = requests.get(url).content\n",
        "tables = pd.read_html(html)\n",
        "\n",
        "dateMap = {\n",
        "    \"Yanvar\": \"1\",\n",
        "    \"Fevral\": \"2\",\n",
        "    \"Mart\": \"3\",\n",
        "    \"Aprel\": \"4\",\n",
        "    \"May\": \"5\",\n",
        "    \"İyun\": \"6\",\n",
        "    \"İyul\": \"7\",\n",
        "    \"Avgust\": \"8\",\n",
        "    \"Sentyabr\": \"9\",\n",
        "    \"Oktyabr\": \"10\",\n",
        "    \"Noyabr\": \"11\",\n",
        "    \"Dekabr\": \"12\"\n",
        "}\n",
        "\n",
        "\n",
        "print(\"len of tables: \", len(tables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WE-K0q8D5AdK"
      },
      "outputs": [],
      "source": [
        "tableMap = {}\n",
        "year = 2023\n",
        "q = 2\n",
        "\n",
        "for index, table in enumerate(tables):\n",
        "  if(index in (0, 1, 2)):\n",
        "    continue\n",
        "  if(year <= 2015):\n",
        "    table = table.iloc[4:]\n",
        "  else:\n",
        "    table = table.iloc[5:]\n",
        "  n_rows = len(table)\n",
        "  pattern = np.tile([True, True, True, False], n_rows // 4 + 1)[:n_rows]\n",
        "  tableMap[str(f\"{year}_{q}\")] = table[pattern]\n",
        "  if(q == 2):\n",
        "    tableMap[str(f\"{year}_{q}\")] = tableMap[str(f\"{year}_{q}\")].rename(columns={0: 'City', 1: 'Type', 2: f'July_{year}', 3: f'August_{year}', 4: f'September_{year}', 5: f'October_{year}', 6: f'November_{year}', 7: f'December_{year}'})\n",
        "  else:\n",
        "    tableMap[str(f\"{year}_{q}\")] = tableMap[str(f\"{year}_{q}\")].rename(columns={0: 'City', 1: 'Type', 2: f'January_{year}', 3: f'February_{year}', 4: f'March_{year}', 5: f'April_{year}', 6: f'May_{year}', 7: f'June_{year}'})\n",
        "\n",
        "  year = year - 1 if q == 1 else year\n",
        "  q = 2 if q == 1 else 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVnn-V_WPXe2",
        "outputId": "70980416-7995-40fa-a39c-cada5172b996"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['2023_2', '2023_1', '2022_2', '2022_1', '2021_2', '2021_1', '2020_2', '2020_1', '2019_2', '2019_1', '2018_2', '2018_1', '2017_2', '2017_1', '2016_2', '2016_1', '2015_2', '2015_1', '2014_2', '2014_1', '2013_2', '2013_1', '2012_2'])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tableMap.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "chy6Tm20QODj"
      },
      "outputs": [],
      "source": [
        "processedMap = {}\n",
        "tableMap.pop(\"2012_2\")\n",
        "not_used_cities = [\"Gəncə\", \"Abşeron rayonu, Xırdalan, Masazır\", \"Sumqayıt\", ]\n",
        "\n",
        "for keys in tableMap.keys():\n",
        "    if(keys[-1] == '2'):\n",
        "        continue\n",
        "    processedMap[keys[:-2]] = pd.concat([tableMap[keys], tableMap[f\"{keys[:-1]}2\"]], axis=1)\n",
        "    processedMap[keys[:-2]] = processedMap[keys[:-2]].loc[:,~processedMap[keys[:-2]].columns.duplicated()].copy()\n",
        "    processedMap[keys[:-2]] = processedMap[keys[:-2]][~processedMap[keys[:-2]].applymap(lambda x: x in not_used_cities).any(axis=1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sFis7A3UQXL2"
      },
      "outputs": [],
      "source": [
        "keys = list(processedMap.keys())\n",
        "finalDf = processedMap[\"2013\"]\n",
        "\n",
        "for key in keys[::-1]:\n",
        "    if key == '2013':\n",
        "        continue\n",
        "\n",
        "    finalDf = pd.merge(finalDf, processedMap[key], on=['City', 'Type'], how='inner')\n",
        "\n",
        "finalDf.fillna(method='ffill', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gib_19uxYtrv",
        "outputId": "fa78d7d6-4155-4aba-ed7d-296a9792fcd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total '-' count across the DataFrame: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "finalDf[\"Type\"] = label_encoder.fit_transform(finalDf['Type'])\n",
        "\n",
        "count_df = finalDf.applymap(lambda x: x.count('-') if isinstance(x, str) else 0)\n",
        "total_count = count_df.sum().sum()\n",
        "\n",
        "\n",
        "while total_count != 0:\n",
        "  for i, row in finalDf.iterrows():\n",
        "      for j in range(1, len(finalDf.columns)):\n",
        "          if row[j] == '-':\n",
        "            finalDf.iat[i, j] = row[j-1]\n",
        "  count_df = finalDf.applymap(lambda x: x.count('-') if isinstance(x, str) else 0)\n",
        "  total_count = count_df.sum().sum()\n",
        "\n",
        "\n",
        "for column in finalDf.columns:\n",
        "  if(column in (\"City\", \"Type\")): continue\n",
        "  finalDf[column] = finalDf[column].str.replace(',', '.')\n",
        "  finalDf[column] = finalDf[column].astype(str).str.replace('\\xa0', ' ', regex=False)\n",
        "  finalDf[column] = finalDf[column].str.replace(' ', '')\n",
        "  finalDf[column] = finalDf[column].astype(float)\n",
        "\n",
        "\n",
        "count_df = finalDf.applymap(lambda x: x.count('-') if isinstance(x, str) else 0)\n",
        "\n",
        "total_count = count_df.sum().sum()\n",
        "\n",
        "print(\"Total '-' count across the DataFrame:\", total_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VML1WmdyVp-f",
        "outputId": "aef8f47b-0a46-4d31-bd02-4b971525f018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "121/121 [==============================] - 2s 3ms/step - loss: 0.0192\n",
            "Epoch 2/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 3/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 5/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 6/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 8.8998e-04\n",
            "Epoch 7/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.0481e-04\n",
            "Epoch 8/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 6.6594e-04\n",
            "Epoch 9/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 5.6764e-04\n",
            "Epoch 10/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 6.5537e-04\n",
            "Epoch 11/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.7114e-04\n",
            "Epoch 12/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 5.0284e-04\n",
            "Epoch 13/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 4.5592e-04\n",
            "Epoch 14/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 4.9260e-04\n",
            "Epoch 15/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 5.2237e-04\n",
            "Epoch 16/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 4.6673e-04\n",
            "Epoch 17/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 4.3853e-04\n",
            "Epoch 18/200\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 3.9450e-04\n",
            "Epoch 19/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.9413e-04\n",
            "Epoch 20/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 4.1603e-04\n",
            "Epoch 21/200\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 3.9907e-04\n",
            "Epoch 22/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.8795e-04\n",
            "Epoch 23/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.7744e-04\n",
            "Epoch 24/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.3228e-04\n",
            "Epoch 25/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.3250e-04\n",
            "Epoch 26/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.0450e-04\n",
            "Epoch 27/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 3.2063e-04\n",
            "Epoch 28/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.3791e-04\n",
            "Epoch 29/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.4889e-04\n",
            "Epoch 30/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.3071e-04\n",
            "Epoch 31/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.8409e-04\n",
            "Epoch 32/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2470e-04\n",
            "Epoch 33/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.8483e-04\n",
            "Epoch 34/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.8770e-04\n",
            "Epoch 35/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.8552e-04\n",
            "Epoch 36/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.7893e-04\n",
            "Epoch 37/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.8410e-04\n",
            "Epoch 38/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.1236e-04\n",
            "Epoch 39/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.5563e-04\n",
            "Epoch 40/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.0072e-04\n",
            "Epoch 41/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2037e-04\n",
            "Epoch 42/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.8759e-04\n",
            "Epoch 43/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6046e-04\n",
            "Epoch 44/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 2.6312e-04\n",
            "Epoch 45/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3882e-04\n",
            "Epoch 46/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3801e-04\n",
            "Epoch 47/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1069e-04\n",
            "Epoch 48/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.0514e-04\n",
            "Epoch 49/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.5932e-04\n",
            "Epoch 50/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.5970e-04\n",
            "Epoch 51/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3951e-04\n",
            "Epoch 52/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 2.0236e-04\n",
            "Epoch 53/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1727e-04\n",
            "Epoch 54/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.0649e-04\n",
            "Epoch 55/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.0539e-04\n",
            "Epoch 56/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.6933e-04\n",
            "Epoch 57/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.8185e-04\n",
            "Epoch 58/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2937e-04\n",
            "Epoch 59/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2701e-04\n",
            "Epoch 60/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1072e-04\n",
            "Epoch 61/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8881e-04\n",
            "Epoch 62/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9203e-04\n",
            "Epoch 63/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.7771e-04\n",
            "Epoch 64/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9255e-04\n",
            "Epoch 65/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.6978e-04\n",
            "Epoch 66/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8127e-04\n",
            "Epoch 67/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7260e-04\n",
            "Epoch 68/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8079e-04\n",
            "Epoch 69/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.6280e-04\n",
            "Epoch 70/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.4068e-04\n",
            "Epoch 71/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5668e-04\n",
            "Epoch 72/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9410e-04\n",
            "Epoch 73/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7746e-04\n",
            "Epoch 74/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7477e-04\n",
            "Epoch 75/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7209e-04\n",
            "Epoch 76/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7708e-04\n",
            "Epoch 77/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.7776e-04\n",
            "Epoch 78/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.0796e-04\n",
            "Epoch 79/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.1342e-04\n",
            "Epoch 80/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.6824e-04\n",
            "Epoch 81/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8216e-04\n",
            "Epoch 82/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5347e-04\n",
            "Epoch 83/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7668e-04\n",
            "Epoch 84/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5719e-04\n",
            "Epoch 85/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4567e-04\n",
            "Epoch 86/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7534e-04\n",
            "Epoch 87/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8049e-04\n",
            "Epoch 88/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1005e-04\n",
            "Epoch 89/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.6483e-04\n",
            "Epoch 90/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1161e-04\n",
            "Epoch 91/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9271e-04\n",
            "Epoch 92/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7535e-04\n",
            "Epoch 93/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4686e-04\n",
            "Epoch 94/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5179e-04\n",
            "Epoch 95/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4006e-04\n",
            "Epoch 96/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4823e-04\n",
            "Epoch 97/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.9755e-04\n",
            "Epoch 98/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.5447e-04\n",
            "Epoch 99/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.8418e-04\n",
            "Epoch 100/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.7867e-04\n",
            "Epoch 101/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.6439e-04\n",
            "Epoch 102/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4121e-04\n",
            "Epoch 103/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4117e-04\n",
            "Epoch 104/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1697e-04\n",
            "Epoch 105/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2537e-04\n",
            "Epoch 106/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.6559e-04\n",
            "Epoch 107/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5151e-04\n",
            "Epoch 108/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8052e-04\n",
            "Epoch 109/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4371e-04\n",
            "Epoch 110/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7650e-04\n",
            "Epoch 111/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3140e-04\n",
            "Epoch 112/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2512e-04\n",
            "Epoch 113/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.5084e-04\n",
            "Epoch 114/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.4052e-04\n",
            "Epoch 115/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2519e-04\n",
            "Epoch 116/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3833e-04\n",
            "Epoch 117/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2465e-04\n",
            "Epoch 118/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4025e-04\n",
            "Epoch 119/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.3378e-04\n",
            "Epoch 120/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.3979e-04\n",
            "Epoch 121/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.4008e-04\n",
            "Epoch 122/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3944e-04\n",
            "Epoch 123/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3444e-04\n",
            "Epoch 124/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1619e-04\n",
            "Epoch 125/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5820e-04\n",
            "Epoch 126/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7750e-04\n",
            "Epoch 127/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5776e-04\n",
            "Epoch 128/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.6664e-04\n",
            "Epoch 129/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8153e-04\n",
            "Epoch 130/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5250e-04\n",
            "Epoch 131/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.7595e-04\n",
            "Epoch 132/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.4733e-04\n",
            "Epoch 133/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5026e-04\n",
            "Epoch 134/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.8413e-04\n",
            "Epoch 135/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5359e-04\n",
            "Epoch 136/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4401e-04\n",
            "Epoch 137/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1467e-04\n",
            "Epoch 138/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5618e-04\n",
            "Epoch 139/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2230e-04\n",
            "Epoch 140/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.5513e-04\n",
            "Epoch 141/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.5979e-04\n",
            "Epoch 142/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.4170e-04\n",
            "Epoch 143/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3696e-04\n",
            "Epoch 144/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3604e-04\n",
            "Epoch 145/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2056e-04\n",
            "Epoch 146/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4334e-04\n",
            "Epoch 147/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3338e-04\n",
            "Epoch 148/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2547e-04\n",
            "Epoch 149/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1279e-04\n",
            "Epoch 150/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3281e-04\n",
            "Epoch 151/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.2842e-04\n",
            "Epoch 152/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1676e-04\n",
            "Epoch 153/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2988e-04\n",
            "Epoch 154/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4361e-04\n",
            "Epoch 155/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3419e-04\n",
            "Epoch 156/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3602e-04\n",
            "Epoch 157/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4598e-04\n",
            "Epoch 158/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.2880e-04\n",
            "Epoch 159/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2083e-04\n",
            "Epoch 160/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3236e-04\n",
            "Epoch 161/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.4192e-04\n",
            "Epoch 162/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.4748e-04\n",
            "Epoch 163/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.4356e-04\n",
            "Epoch 164/200\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 1.3434e-04\n",
            "Epoch 165/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.3813e-04\n",
            "Epoch 166/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3537e-04\n",
            "Epoch 167/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2752e-04\n",
            "Epoch 168/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3640e-04\n",
            "Epoch 169/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2885e-04\n",
            "Epoch 170/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3378e-04\n",
            "Epoch 171/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3316e-04\n",
            "Epoch 172/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1794e-04\n",
            "Epoch 173/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3539e-04\n",
            "Epoch 174/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2676e-04\n",
            "Epoch 175/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3748e-04\n",
            "Epoch 176/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2645e-04\n",
            "Epoch 177/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 9.9506e-05\n",
            "Epoch 178/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4824e-04\n",
            "Epoch 179/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.2999e-04\n",
            "Epoch 180/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2582e-04\n",
            "Epoch 181/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3271e-04\n",
            "Epoch 182/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2591e-04\n",
            "Epoch 183/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.2587e-04\n",
            "Epoch 184/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.1201e-04\n",
            "Epoch 185/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.1767e-04\n",
            "Epoch 186/200\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 1.1318e-04\n",
            "Epoch 187/200\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 1.1949e-04\n",
            "Epoch 188/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.1607e-04\n",
            "Epoch 189/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.4235e-04\n",
            "Epoch 190/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.5921e-04\n",
            "Epoch 191/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.3007e-04\n",
            "Epoch 192/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1937e-04\n",
            "Epoch 193/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.1407e-04\n",
            "Epoch 194/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1980e-04\n",
            "Epoch 195/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.2268e-04\n",
            "Epoch 196/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.1948e-04\n",
            "Epoch 197/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.2362e-04\n",
            "Epoch 198/200\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1.1381e-04\n",
            "Epoch 199/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.0168e-04\n",
            "Epoch 200/200\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 1.1073e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79e46eaa1210>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def filter_data(city, type_, df):\n",
        "  return df[(df['City'] == city) & (df['Type'] == type_)].select_dtypes(include=[np.number])\n",
        "\n",
        "city = 'Nərimanov'\n",
        "type_ = 0\n",
        "filtered_df = filter_data(city, type_, finalDf)\n",
        "\n",
        "data = filtered_df.values\n",
        "data = data.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "n_input = 12\n",
        "n_features = 1\n",
        "\n",
        "generator = TimeseriesGenerator(data_scaled, data_scaled, length=n_input, batch_size=1)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_input, n_features)),\n",
        "    Conv1D(filters=32, kernel_size=2, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='nadam', loss='mse')\n",
        "\n",
        "\n",
        "model.fit(generator, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ii0KbklVtcJZ"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik8z_Y25eKeD",
        "outputId": "d6b2ab71-81b0-459d-983c-8a1a5a4c03f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0.  ]\n",
            " [1133.55]\n",
            " [1129.33]\n",
            " [1150.94]\n",
            " [1193.44]\n",
            " [1208.61]\n",
            " [1186.02]\n",
            " [1206.26]\n",
            " [1217.31]\n",
            " [1264.55]\n",
            " [1310.07]\n",
            " [1295.14]\n",
            " [1298.33]\n",
            " [1327.83]\n",
            " [1398.14]\n",
            " [1477.51]\n",
            " [1498.31]\n",
            " [1545.24]\n",
            " [1523.28]\n",
            " [1524.02]\n",
            " [1577.93]\n",
            " [1586.5 ]\n",
            " [1584.06]\n",
            " [1578.82]\n",
            " [1543.42]\n",
            " [1495.76]\n",
            " [1495.76]\n",
            " [1545.54]\n",
            " [1547.2 ]\n",
            " [1539.31]\n",
            " [1537.89]\n",
            " [1501.46]\n",
            " [1494.15]\n",
            " [1444.38]\n",
            " [1408.28]\n",
            " [1385.13]\n",
            " [1385.13]\n",
            " [1406.23]\n",
            " [1430.6 ]\n",
            " [1445.67]\n",
            " [1448.71]\n",
            " [1439.17]\n",
            " [1437.86]\n",
            " [1434.06]\n",
            " [1436.02]\n",
            " [1392.73]\n",
            " [1399.49]\n",
            " [1440.71]\n",
            " [1451.08]\n",
            " [1454.26]\n",
            " [1472.35]\n",
            " [1479.67]\n",
            " [1468.1 ]\n",
            " [1458.64]\n",
            " [1433.35]\n",
            " [1415.63]\n",
            " [1407.83]\n",
            " [1411.97]\n",
            " [1424.94]\n",
            " [1400.01]\n",
            " [1411.73]\n",
            " [1398.01]\n",
            " [1393.85]\n",
            " [1400.71]\n",
            " [1418.02]\n",
            " [1413.02]\n",
            " [1396.82]\n",
            " [1425.52]\n",
            " [1420.61]\n",
            " [1422.69]\n",
            " [1426.46]\n",
            " [1426.35]\n",
            " [1434.  ]\n",
            " [1444.58]\n",
            " [1442.01]\n",
            " [1457.99]\n",
            " [1417.15]\n",
            " [1410.74]\n",
            " [1424.94]\n",
            " [1448.91]\n",
            " [1447.23]\n",
            " [1467.46]\n",
            " [1483.38]\n",
            " [1496.24]\n",
            " [1491.3 ]\n",
            " [1503.09]\n",
            " [1514.77]\n",
            " [1514.77]\n",
            " [1534.96]\n",
            " [1514.36]\n",
            " [1521.61]\n",
            " [1533.39]\n",
            " [1550.17]\n",
            " [1572.9 ]\n",
            " [1572.9 ]\n",
            " [1561.77]\n",
            " [1557.7 ]\n",
            " [1567.76]\n",
            " [1569.15]\n",
            " [1578.41]\n",
            " [1574.28]\n",
            " [1607.24]\n",
            " [1598.29]\n",
            " [1596.59]\n",
            " [1599.57]\n",
            " [1609.89]\n",
            " [1617.43]\n",
            " [1638.11]\n",
            " [1653.63]\n",
            " [1674.84]\n",
            " [1674.84]\n",
            " [1674.53]\n",
            " [1674.53]\n",
            " [1720.15]\n",
            " [1720.15]\n",
            " [1721.2 ]\n",
            " [1721.2 ]\n",
            " [1747.14]\n",
            " [1747.14]\n",
            " [1802.55]\n",
            " [1802.55]\n",
            " [1933.19]\n",
            " [1933.19]\n",
            " [1984.18]\n",
            " [1984.18]\n",
            " [2037.48]\n",
            " [2037.48]\n",
            " [2107.12]\n",
            " [2107.12]\n",
            " [2132.05]\n",
            " [2132.05]\n",
            " [2147.68]\n",
            " [2147.68]]\n",
            "[[0.        ]\n",
            " [0.52780209]\n",
            " [0.52583718]\n",
            " [0.5358992 ]\n",
            " [0.555688  ]\n",
            " [0.56275143]\n",
            " [0.55223311]\n",
            " [0.56165723]\n",
            " [0.56680232]\n",
            " [0.58879814]\n",
            " [0.60999311]\n",
            " [0.60304142]\n",
            " [0.60452675]\n",
            " [0.6182625 ]\n",
            " [0.65100015]\n",
            " [0.68795631]\n",
            " [0.69764118]\n",
            " [0.71949266]\n",
            " [0.70926767]\n",
            " [0.70961223]\n",
            " [0.73471374]\n",
            " [0.73870409]\n",
            " [0.73756798]\n",
            " [0.73512814]\n",
            " [0.71864524]\n",
            " [0.69645385]\n",
            " [0.69645385]\n",
            " [0.71963235]\n",
            " [0.72040527]\n",
            " [0.71673154]\n",
            " [0.71607036]\n",
            " [0.69910787]\n",
            " [0.6957042 ]\n",
            " [0.67253036]\n",
            " [0.65572152]\n",
            " [0.64494245]\n",
            " [0.64494245]\n",
            " [0.654767  ]\n",
            " [0.66611413]\n",
            " [0.67313101]\n",
            " [0.67454649]\n",
            " [0.67010448]\n",
            " [0.66949452]\n",
            " [0.66772517]\n",
            " [0.66863779]\n",
            " [0.64848115]\n",
            " [0.65162873]\n",
            " [0.67082154]\n",
            " [0.67565   ]\n",
            " [0.67713067]\n",
            " [0.68555371]\n",
            " [0.68896204]\n",
            " [0.68357483]\n",
            " [0.67917008]\n",
            " [0.66739458]\n",
            " [0.65914382]\n",
            " [0.65551199]\n",
            " [0.65743966]\n",
            " [0.66347873]\n",
            " [0.65187086]\n",
            " [0.65732791]\n",
            " [0.65093962]\n",
            " [0.64900264]\n",
            " [0.65219679]\n",
            " [0.66025665]\n",
            " [0.65792856]\n",
            " [0.65038553]\n",
            " [0.66374879]\n",
            " [0.6614626 ]\n",
            " [0.66243109]\n",
            " [0.66418647]\n",
            " [0.66413525]\n",
            " [0.66769724]\n",
            " [0.67262348]\n",
            " [0.67142684]\n",
            " [0.67886743]\n",
            " [0.65985156]\n",
            " [0.65686694]\n",
            " [0.66347873]\n",
            " [0.67463961]\n",
            " [0.67385737]\n",
            " [0.68327684]\n",
            " [0.69068949]\n",
            " [0.69667734]\n",
            " [0.69437719]\n",
            " [0.69986683]\n",
            " [0.70530526]\n",
            " [0.70530526]\n",
            " [0.7147061 ]\n",
            " [0.70511436]\n",
            " [0.70849009]\n",
            " [0.71397508]\n",
            " [0.72178816]\n",
            " [0.73237168]\n",
            " [0.73237168]\n",
            " [0.72718934]\n",
            " [0.72529427]\n",
            " [0.7299784 ]\n",
            " [0.73062561]\n",
            " [0.73493723]\n",
            " [0.73301423]\n",
            " [0.74836102]\n",
            " [0.74419373]\n",
            " [0.74340218]\n",
            " [0.74478973]\n",
            " [0.74959491]\n",
            " [0.75310568]\n",
            " [0.76273467]\n",
            " [0.76996107]\n",
            " [0.77983685]\n",
            " [0.77983685]\n",
            " [0.77969251]\n",
            " [0.77969251]\n",
            " [0.80093403]\n",
            " [0.80093403]\n",
            " [0.80142293]\n",
            " [0.80142293]\n",
            " [0.81350108]\n",
            " [0.81350108]\n",
            " [0.83930101]\n",
            " [0.83930101]\n",
            " [0.90012944]\n",
            " [0.90012944]\n",
            " [0.92387134]\n",
            " [0.92387134]\n",
            " [0.94868882]\n",
            " [0.94868882]\n",
            " [0.9811145 ]\n",
            " [0.9811145 ]\n",
            " [0.99272238]\n",
            " [0.99272238]\n",
            " [1.        ]\n",
            " [1.        ]]\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "Predicted next value: 2220.252197265625\n"
          ]
        }
      ],
      "source": [
        "filtered_df = filter_data(city, type_, finalDf)\n",
        "\n",
        "city = 'Yasamal'\n",
        "type_ = 0\n",
        "data = filtered_df.values\n",
        "data = data.reshape(-1, 1)\n",
        "print(data)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "print(data_scaled)\n",
        "\n",
        "\n",
        "last_sequence = data_scaled[-n_input:].reshape((1, n_input, n_features))\n",
        "predicted_scaled = model.predict(last_sequence)\n",
        "\n",
        "predicted = scaler.inverse_transform(predicted_scaled)\n",
        "\n",
        "print(f\"Predicted next value: {predicted[0][0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52q-Wmi5tlrg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
